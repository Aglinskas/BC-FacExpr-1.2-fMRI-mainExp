{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "401e2b34-2a98-4e6a-ab5f-c11a6434355a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/aidasaglinskas/Desktop/BC-FacExpr-1.2-fMRI-mainExp/scripts_python'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30d31485-02f9-455d-b50f-1e2ecb255dc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:228: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n"
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image, ImageEnhance,ImageStat\n",
    "import skvideo\n",
    "import skvideo.io\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import alignfaces as afa\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21d8349b-da2b-4df2-907e-c8427bab5f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_mkdir(dir_name):\n",
    "    if not os.path.exists(dir_name):\n",
    "        os.mkdir(dir_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25a53c9a-db04-45f4-ad84-8dcfb7960051",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_video(fn):\n",
    "    #fn = 'ID4_h1_1.mp4'\n",
    "    videodata = skvideo.io.vread(fn)\n",
    "    return videodata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7347e00-ea9b-470e-89c3-2f4983f216d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_video(videodata,ofn='outvideo.mp4'):\n",
    "    #skvideo.io.vwrite(ofn, videodata.astype(np.uint8),outputdict={'-codec': 'h264', '-filter:v' : 'fps=29.97'})\n",
    "    skvideo.io.vwrite(ofn, videodata.astype(np.uint8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96607699-1f13-4540-ac96-ba89530dace8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# files = [os.path.join('./stimuli/',file) for file in os.listdir('./stimuli/') if file.endswith('.mp4')]\n",
    "# files.sort()\n",
    "# files[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "60d9aab5-1a36-410c-bb5f-d23bb29b8ef6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../stimuli/stimuli_raw/id1d1.mp4',\n",
       " '../stimuli/stimuli_raw/id1d2.mp4',\n",
       " '../stimuli/stimuli_raw/id1f1.mp4',\n",
       " '../stimuli/stimuli_raw/id1f2.mp4',\n",
       " '../stimuli/stimuli_raw/id1h1.mp4']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indir = '../stimuli/stimuli_raw/'\n",
    "files = [os.path.join(indir,file) for file in os.listdir(indir) if file.endswith('.mp4')]\n",
    "files.sort()\n",
    "files[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "305d54c4-a0ed-4a9e-acd1-32c5afb4af95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_into_frames(vid_fn):\n",
    "    videodata = load_video(vid_fn)\n",
    "    nframes = videodata.shape[0]\n",
    "    frame_filenames = []\n",
    "    for f in range(nframes):\n",
    "        frame = videodata[f,:,:,:]\n",
    "        frame_ofn = vid_fn.replace('.mp4','').replace('./stimuli/','./stimuli_pics/')+f'frame-{f}.png'\n",
    "        frame_filenames.append(frame_ofn)\n",
    "        Image.fromarray(frame).save(frame_ofn)\n",
    "    return frame_filenames,videodata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0293a1a4-ee32-44ef-b2c6-4a207744c4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "do_split = False\n",
    "if do_split:\n",
    "    for file in tqdm(files):\n",
    "        split_into_frames(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "64e9fa23-1b48-450b-a88d-62445d55fadf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_video_frames(vid_fn):\n",
    "    vid_name = vid_fn.split('/')[-1].replace('.mp4','')\n",
    "    frames_bad = [i for i in os.listdir('./stimuli_pics/') if i.startswith(vid_name)]\n",
    "    frames = [f'./stimuli_pics/{vid_name}frame-{i:01d}.png' for i in range(len(frames_bad))]\n",
    "    return frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f1d5ac80-78c2-41fe-91ed-0ce16276c6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_frame(image_fn,enlarge=0):\n",
    "    \n",
    "    trained_data = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "    img = cv2.imread(image_fn)\n",
    "    gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    face_cordinates = trained_data.detectMultiScale(gray_img)\n",
    "    face_cordinates = face_cordinates + [-enlarge,-enlarge,enlarge*2,enlarge*2]\n",
    "    \n",
    "    return face_cordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ebd14452-62f4-432a-814d-1107e89f2f45",
   "metadata": {},
   "outputs": [],
   "source": [
    " def crop_frame_to_rect(image_fn,rect,debug=False):\n",
    "    img = cv2.imread(image_fn)\n",
    "    img2 = cv2.imread(image_fn)\n",
    "    for (x, y, w, h) in rect:\n",
    "        cv2.rectangle(img, (x, y), (x+w, y+h), (0, 0, 0), -2)\n",
    "        \n",
    "    img2[img!=0]=0\n",
    "\n",
    "    if debug==False:\n",
    "        return img2\n",
    "    else:\n",
    "        return img2,img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9a7c3fa6-fb7e-41bd-844a-a58795f5c9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rect_size(mean_frame):\n",
    "    for (x, y, w, h) in rect:\n",
    "        size = w*h\n",
    "    return size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "04fde738-28ca-44ad-83a0-6f917b5c9d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_cropped(frame_filenames,videodata,vid_ofn):\n",
    "    mask = np.array([crop_frame(frame_filename)[1] for frame_filename in frame_filenames])\n",
    "    vid_mask = ((mask==0).sum(-1)==3).sum(axis=0)>1    \n",
    "    videodata_cropped = videodata.copy()\n",
    "    nframes = videodata_cropped.shape[0]\n",
    "    for f in range(nframes):\n",
    "        for c in range(3):\n",
    "            videodata_cropped[f,:,:,c][~vid_mask]=0\n",
    "            \n",
    "    save_video(videodata_cropped,ofn=vid_ofn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d574f199-d3e6-4daf-96d6-69290cde0770",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_video(video_data,vid_size_target=(512,512)):\n",
    "    from PIL import Image, ImageEnhance,ImageStat\n",
    "    import numpy as np\n",
    "    \n",
    "    #vid_size_target = np.array((512,512))\n",
    "    vid_size_target = np.array(vid_size_target)\n",
    "    vid_size = np.array((video_data.shape[1],video_data.shape[2]))\n",
    "    nframes = video_data.shape[0]\n",
    "    nchannels = video_data.shape[-1]\n",
    "    video_data_new = np.zeros((nframes,vid_size_target[0],vid_size_target[1],nchannels))\n",
    "    for f in range(nframes):\n",
    "        video_data_new[f,:,:,:] = np.array(Image.fromarray(video_data[f,:,:,:]).resize(vid_size_target,Image.ANTIALIAS))\n",
    "\n",
    "    return video_data_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8156f75c-6d0f-4515-85e3-aa57af2dd100",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_video(video_data,vid_size_target=(512,512)):\n",
    "    from PIL import Image, ImageEnhance,ImageStat\n",
    "    import numpy as np\n",
    "    \n",
    "    #vid_size_target = np.array((512,512))\n",
    "    vid_size_target = np.array(vid_size_target)\n",
    "    vid_size = np.array((video_data.shape[1],video_data.shape[2]))\n",
    "    nframes = video_data.shape[0]\n",
    "    nchannels = video_data.shape[-1]\n",
    "    video_data_new = np.zeros((nframes,vid_size_target[0],vid_size_target[1],nchannels))\n",
    "    for f in range(nframes):\n",
    "        video_data_new[f,:,:,:] = np.array(Image.fromarray(video_data[f,:,:,:]).resize(vid_size_target[-1::-1],Image.ANTIALIAS))\n",
    "        \n",
    "    return video_data_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7e4c39a1-e758-4b73-8097-0a11bb8f4c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_frame2(img,enlarge=0):\n",
    "    \n",
    "    trained_data = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "    #img = cv2.imread(image_fn)\n",
    "    gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    face_cordinates = trained_data.detectMultiScale(gray_img)\n",
    "    face_cordinates = face_cordinates + [-enlarge,-enlarge,enlarge*2,enlarge*2]\n",
    "    \n",
    "    return face_cordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8888c6e7-e86e-4a5f-832f-d89ae668cd46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_video_to_rect2(video_data,x,y,h,w):\n",
    "    return np.array([crop_frame_to_rect2(video_data[i,:,:,:],x, y, w, h) for i in range(video_data.shape[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9dc286a0-e890-4a91-9a5d-5e912187e9ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_frame_to_rect2(img,x,y,h,w):\n",
    "    return img[np.arange(y,y+h),:,:][:,np.arange(x,x+w),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "181c25eb-6e0f-4ab8-8bdc-8e079b22c9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_frame(img_face,pad_amount=100):\n",
    "    arr = np.array([np.pad(img_face[:,:,0], (pad_amount, pad_amount), mode='constant'),\n",
    "    np.pad(img_face[:,:,1], (pad_amount, pad_amount), mode='constant'),\n",
    "    np.pad(img_face[:,:,2], (pad_amount, pad_amount), mode='constant'),])\n",
    "    arr = np.swapaxes(arr,0,1)\n",
    "    arr = np.swapaxes(arr,1,2)\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231ff723-ca24-4eae-9915-05b698070d1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f742d8-37ee-4a56-baba-70877dfa9881",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "15715404-c7af-4e37-a8b8-89440e1415be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vid_fn = files[0]\n",
    "# video_data = load_video(vid_fn)\n",
    "\n",
    "# frame_rects = np.array([return_frame2(video_data[i,:,:,:],enlarge=60)[0] for i in range(video_data.shape[0])])\n",
    "# mean_frame = frame_rects.mean(axis=0).astype(int)\n",
    "# x, y, w, h = mean_frame\n",
    "# video_data_cropped = crop_video_to_rect2(video_data,x,y,h,w)\n",
    "# video_data_cropped = resize_video(video_data_cropped,vid_size_target=(512,512))\n",
    "\n",
    "\n",
    "# plt.imshow(video_data_cropped[0,:,:,:].astype(np.uint8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ca3bae38-11a1-4ba0-b35b-088b752d0823",
   "metadata": {},
   "outputs": [],
   "source": [
    "ofdir = '../stimuli/stimuli_working_dir/stimuli_cropped/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "e9c4ddf9-df38-4b43-bcdc-796565df27e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 10/10 [03:00<00:00, 18.07s/it]\n"
     ]
    }
   ],
   "source": [
    "# Left messy Aidas fix\n",
    "do_crop = True\n",
    "if do_crop:\n",
    "    safe_mkdir(ofdir)\n",
    "    for vid_fn in tqdm(files[30:40]):\n",
    "        ofn = vid_fn.replace(indir,ofdir)\n",
    "        ofn = ofn.replace('.mp4',f'_crop-{crop}.mp4')\n",
    "        if not os.path.exists(ofn):\n",
    "\n",
    "            video_data = load_video(vid_fn)\n",
    "\n",
    "            frame_rects = np.array([return_frame2(video_data[i,:,:,:],enlarge=crop)[0] for i in range(video_data.shape[0])])\n",
    "            mean_frame = frame_rects.mean(axis=0).astype(int)\n",
    "            x, y, w, h = mean_frame\n",
    "            video_data_cropped = crop_video_to_rect2(video_data,x,y,h,w)\n",
    "            video_data_cropped = resize_video(video_data_cropped,vid_size_target=(512,512))\n",
    "\n",
    "\n",
    "            save_video(video_data_cropped,ofn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d140ca6d-5253-4773-85bb-8bc15a26379d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d901e7-88b3-40ad-9201-c7e22f8ab681",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8150d6-8516-4cb9-a767-abde61ccf51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# frame_check = []\n",
    "# for i in range(len(files)):\n",
    "#     frame_check.append(\n",
    "#                 load_video(files[i]).shape[0] == load_video(files[i].replace('./stimuli/','./stimuli_cropped/')).shape[0]\n",
    "#                     )\n",
    "# assert all(frame_check), 'n frame mistmach'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "88289888-cf23-4076-b151-1544db9eaef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# files_where = './stimuli_cropped'\n",
    "# files_which = [file for file in os.listdir(files_where) if file.endswith('.mp4')]\n",
    "# files_which.sort()\n",
    "# nfiles = len(files_which)\n",
    "# print(nfiles)\n",
    "# files_which[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b35842-af1e-4325-b246-2b320354e5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_small_vid(i):\n",
    "#     return resize_video(load_video(os.path.join(files_where,files_which[i])),vid_size_target=(64,64)).mean(axis=-1).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "eedfbac2-a0c2-49cb-b795-57c5096202f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#flat_mat = np.array([load_video(os.path.join(files_where,files_which[i])).flatten()[0::1000] for i in tqdm(range(nfiles))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b95108cf-f6ff-40f4-a531-d96b1da06049",
   "metadata": {},
   "outputs": [],
   "source": [
    "#flat_mat = np.array([get_small_vid(i)[0:50:2,:,:].flatten() for i in tqdm(range(nfiles))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d213176e-06b1-41ad-b210-a0cd138bdee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(15,15))\n",
    "# plt.imshow(np.corrcoef(flat_mat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9a16d30c-0ee1-4acf-b0ee-c0cbc1584c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# files = [os.path.join('./stimuli/',file) for file in os.listdir('./stimuli/') if file.endswith('.mp4')]\n",
    "# files.sort()\n",
    "# files[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "447ef787-0044-40d9-a706-030f8623b32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0e155800-064e-42f1-8c56-ef8838b6a163",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_small_vid2(i,crop=0):\n",
    "#     return resize_video(load_video(files[i].replace('.mp4',f'_crop-{crop}.mp4').replace('./stimuli/','./stimuli_cropped/')),(128,128))[0:70:2,:,:,:].mean(axis=-1).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "891a5f12-3164-46f9-9a09-6c41f821c29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_triu(inMat):\n",
    "#     #inMat = rdm_bg\n",
    "\n",
    "#     assert np.ndim(inMat)==2, 'not 2 dim, wtf'\n",
    "#     assert inMat.shape[0]==inMat.shape[1], 'not a square'\n",
    "\n",
    "#     n = inMat.shape[0]\n",
    "#     triu_vec = inMat[np.triu_indices(n=n,k=1)]\n",
    "\n",
    "#     #assert (squareform(triu_vec)==inMat).sum()/(n**2)>.9, 'unfaithful triu'\n",
    "#     return triu_vec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f878bdb3-65e3-49f7-8dc1-2476e3f66be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import random\n",
    "# cmat1 = np.corrcoef(np.array([get_small_vid2(i,crop=0).flatten() for i in tqdm(range(len(files)))]))\n",
    "# #cmat2 = np.corrcoef(np.array([get_small_vid2(i,crop=random.choice([0,10,20,30,40,50,60,70,80,90,100])).flatten() for i in tqdm(range(len(files)))]))\n",
    "# cmat2 = np.corrcoef(np.array([get_small_vid2(i,crop=random.choice([0,20,40,60,80])).flatten() for i in tqdm(range(len(files)))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c9554317-a09b-4dd7-9e4b-d160e3320b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(15,5))\n",
    "# plt.subplot(1,2,1)\n",
    "# plt.imshow(cmat1)\n",
    "# plt.clim(0.5,1)\n",
    "# plt.colorbar()\n",
    "\n",
    "# plt.subplot(1,2,2)\n",
    "# plt.imshow(cmat2)\n",
    "# plt.clim(0.5,1)\n",
    "# plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd42560-daa1-4beb-afcb-df0c9bdc779b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_triu(cmat1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d864d45-c4a3-47c1-8f81-7e464567c047",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_triu(cmat2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1dd0460b-a9b6-4b25-acab-40e672522fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ratios_cmat1 = []\n",
    "# for i in range(7):\n",
    "#     which_rows = np.arange(i*10,i*10+10)\n",
    "#     other_rows = np.array([i for i in np.arange(70) if i not in which_rows])\n",
    "#     within = get_triu(cmat1[which_rows,:][:,which_rows]).mean()\n",
    "#     across = cmat1[which_rows,:][:,other_rows].mean()\n",
    "#     ratio = within/across\n",
    "#     ratios_cmat1.append(ratio)\n",
    "    \n",
    "# ratios_cmat2 = []\n",
    "# for i in range(7):\n",
    "#     which_rows = np.arange(i*10,i*10+10)\n",
    "#     other_rows = np.array([i for i in np.arange(70) if i not in which_rows])\n",
    "#     within = get_triu(cmat2[which_rows,:][:,which_rows]).mean()\n",
    "#     across = cmat2[which_rows,:][:,other_rows].mean()\n",
    "#     ratio = within/across\n",
    "#     ratios_cmat2.append(ratio)\n",
    "    \n",
    "# ratios_cmat2 = np.array(ratios_cmat2)\n",
    "# ratios_cmat1 = np.array(ratios_cmat1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5a0a9a-ff4a-453b-96d5-05e27afe2841",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(ratios_cmat1.mean().round(2))\n",
    "# print(ratios_cmat2.mean().round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d76ebac-c94c-4fc3-a478-2ca2aa473134",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.hist(ratios_cmat1,alpha=.5)\n",
    "# plt.hist(ratios_cmat2,alpha=.5)\n",
    "# plt.legend(['same crop', 'rand crop'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9408ae4c-cf62-41a1-b15d-5778c2181a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scipy.cluster.hierarchy import linkage,dendrogram\n",
    "\n",
    "# Y = 1-get_triu(cmat1)\n",
    "# Z = linkage(Y,'ward')\n",
    "# lbls = [file.split('/')[-1].replace('.mp4','')[2] for file in files]\n",
    "# plt.figure(figsize=(15,5))\n",
    "# dendrogram(Z,0,labels=lbls,orientation='top',leaf_font_size=12,color_threshold=.5,leaf_rotation=0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8b18fc0c-15f3-4c3e-9a60-f6fafae4b42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scipy.cluster.hierarchy import linkage,dendrogram\n",
    "\n",
    "# Y = 1-get_triu(cmat2)\n",
    "# Z = linkage(Y,'ward')\n",
    "# lbls = [file.split('/')[-1].replace('.mp4','')[2] for file in files]\n",
    "# plt.figure(figsize=(15,5))\n",
    "# dendrogram(Z,0,labels=lbls,orientation='top',leaf_font_size=12,color_threshold=.5,leaf_rotation=0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b617545-7a82-4d71-965f-68c5cd6385d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e41ef086-38af-4117-83a0-857403dccfed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca169183-bea1-4ce6-ab46-48fe3c85ee88",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
